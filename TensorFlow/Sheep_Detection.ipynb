{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sheep_Detection(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks1hhNHjvRsH"
      },
      "source": [
        "#Step 1- Download this repository and upload to \"/content/gdrive/My Drive\" that is in your google drive.\r\n",
        "#After that your folders will seen like below.\r\n",
        "#Note: Do not forget to change Runtime→Change Runtime Type and select Hardware accelerator as GPU.\r\n",
        "\"\"\"\r\n",
        "TensorFlow\r\n",
        "├───scripts\r\n",
        "│   └───preprocessing\r\n",
        "│     └───generate_tfrecord.py \r\n",
        "└───workspace\r\n",
        "    └───training_demo\r\n",
        "        ├───annotations\r\n",
        "        │   └───label_map.pbtxt \r\n",
        "        ├───content\r\n",
        "        │     └───sheep_videos.mp4 \r\n",
        "        ├───exported-models\r\n",
        "        ├───images\r\n",
        "        │   ├───test\r\n",
        "        │   │     └───test images with corresponding XML files\r\n",
        "        │   └───train\r\n",
        "        │         └───train images with corresponding XML files\r\n",
        "        ├───models\r\n",
        "        │   └───my_ssd_resnet50_v1_fpn\r\n",
        "        └───pre-trained-models\r\n",
        "            └───ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\r\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCBVdQ9VPlUB"
      },
      "source": [
        "#Step 2- Mount Google Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbLbQ3lim8wU"
      },
      "source": [
        "#Step 3- Download TensorFlow Model Garden\r\n",
        "%cd /content/gdrive/My Drive/TensorFlow\r\n",
        "!git clone https://github.com/tensorflow/models\r\n",
        "#You have a new folder named ‘models’ in your 'TensorFlow/' directory!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1knngmNwD6j0",
        "outputId": "6ff04a1a-bb4b-4c1b-d9c3-e5fd25183d3a"
      },
      "source": [
        "#Step 4- Download Pre-trained Model\r\n",
        "%cd /content/gdrive/My Drive/TensorFlow/workspace/training_demo/pre-trained-models\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import glob\r\n",
        "import urllib\r\n",
        "import tarfile\r\n",
        "from requests import get\r\n",
        "\r\n",
        "MODEL = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\r\n",
        "MODEL_FILE = MODEL + '.tar.gz'\r\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\r\n",
        "\r\n",
        "if not (os.path.exists(MODEL_FILE)):\r\n",
        "  with open(MODEL_FILE, \"wb\") as file:\r\n",
        "    # get request\r\n",
        "    response = get(DOWNLOAD_BASE + MODEL_FILE)\r\n",
        "    # write to file\r\n",
        "    file.write(response.content)\r\n",
        "\r\n",
        "tar = tarfile.open(MODEL_FILE)\r\n",
        "tar.extractall()\r\n",
        "tar.close()\r\n",
        "os.remove(MODEL_FILE)\r\n",
        "#You have a pretrained model in your 'TensorFlow/workspace/training_demo/pre-trained-models' directory!\r\n",
        "#Move the 'pipeline.config' file from ‘TensorFlow/workspace/training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8’ to \"TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn\"\r\n",
        "shutil.move(\"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\", \"../models/my_ssd_resnet50_v1_fpn\") \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TensorFlow/workspace/training_demo/pre-trained-models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'../models/pipeline.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akZpmsBFsmf1"
      },
      "source": [
        "#Step 5- Configure the pipeline file.\r\n",
        "#Go to \"TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn\".\r\n",
        "#Open the pipeline.config file.\r\n",
        "#Change the lines shown below\r\n",
        "\"\"\"\r\n",
        "Line 3:\r\n",
        "  num_classes: 1 \r\n",
        "\r\n",
        "Line 131:\r\n",
        "  batch_size: 8\r\n",
        "\r\n",
        "Line 161:\r\n",
        "  fine_tune_checkpoint: \"pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\" (#path to checkpoint of downloaded pre-trained-model)\r\n",
        "\r\n",
        "Line 162:\r\n",
        "  num_steps: 25000 (#maximum number of steps to train model, you can stop model training on any step you wish)\r\n",
        "\r\n",
        "Line 167:\r\n",
        "  fine_tune_checkpoint_type: \"detection\"\r\n",
        "\r\n",
        "Line 168:\r\n",
        "  use_bfloat16: false (#Set this to true only if you are training on a TPU)\r\n",
        "\r\n",
        "Line 172:\r\n",
        "  label_map_path: \"annotations/label_map.pbtxt\" (#path to your label_map file)\r\n",
        "\r\n",
        "Line 174:\r\n",
        "  input_path: \"annotations/train.record\" (#path to train.record)\r\n",
        "\r\n",
        "Line 182:\r\n",
        "  label_map_path: \"annotations/label_map.pbtxt\" (#path to your label_map file)\r\n",
        "\r\n",
        "Line 186:\r\n",
        "  input_path: \"annotations/test.record\" (#Path to test.record)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bqpLTGhgelZ"
      },
      "source": [
        " #Step 6- Install some required libraries and tools\r\n",
        "!apt-get install protobuf-compiler python-lxml python-pil\r\n",
        "!pip install Cython pandas tf-slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTvUOIK1kXV6",
        "outputId": "cc4f0270-12ef-4641-dd3a-47b62974252f"
      },
      "source": [
        "#Step 7- Compile the Protobuf libraries\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\r\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TensorFlow/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzzAU-13lZ_L"
      },
      "source": [
        "#Step 8- Set the environment to Build and Install setup.py.\r\n",
        "import os\r\n",
        "import sys\r\n",
        "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\r\n",
        "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE_D2Mpslftt"
      },
      "source": [
        "#Step 9- Build and Install setup.py.\r\n",
        "!python setup.py build\r\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJGF80AsmN0c"
      },
      "source": [
        "#Step 10- Test the installation.\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\r\n",
        "!python model_builder_tf2_test.py\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71eoV3uVmp7t",
        "outputId": "70a995ed-543b-4ae6-f7ce-1b90a0e9d0e5"
      },
      "source": [
        "#Step 11- Generate Tfrecords\r\n",
        "#cd into preprocessing directory\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'\r\n",
        "#run the cell to generate test.record and train.record\r\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record'\r\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record'\r\n",
        "#You have two new files “test.record” and “train.record” in ‘TensorFlow/workspace/training_demo/workspace/training_demo/annotations’ folder."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/TensorFlow/scripts/preprocessing\n",
            "Successfully created the TFRecord file: /content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UFbJlansFT8"
      },
      "source": [
        "#Step 12- Start TensorBoard\r\n",
        "#cd into training_demo\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\r\n",
        "#start the Tensorboard\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoh5g9sjsO5p"
      },
      "source": [
        "#Step 13- Train the Model\r\n",
        "pip install lvis\r\n",
        "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7lhVFPIvTrz"
      },
      "source": [
        "#Step 14- Export the Trained Model\r\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model\r\n",
        "#You have fine-tuned pretrained model in TensorFlow/workspace/training_demo/exported-models/my_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx7lgBd3v0T7"
      },
      "source": [
        "#Step 15- Loading the saved_model\r\n",
        "import tensorflow as tf\r\n",
        "import time\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "PATH_TO_SAVED_MODEL=\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/my_model/saved_model\"\r\n",
        "print('Loading model...', end='')\r\n",
        "# Load saved model and build the detection function\r\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSNh_KV8wDjg"
      },
      "source": [
        "#Step 16- Loading the label_map\r\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt\",use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPTGAZgdwTGz"
      },
      "source": [
        "#Step 17- Define 'show_inference' function to detection per by per image .\r\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\r\n",
        "\r\n",
        "def show_inference(frame):\r\n",
        "\r\n",
        "    image_np = np.array(frame)\r\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\r\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\r\n",
        "\r\n",
        "    detections=detect_fn(input_tensor)\r\n",
        "    # All outputs are batches tensors.\r\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n",
        "    # We're only interested in the first num_detections.\r\n",
        "    num_detections=int(detections.pop('num_detections'))\r\n",
        "    detections={key:value[0,:num_detections].numpy()\r\n",
        "                   for key,value in detections.items()}\r\n",
        "    detections['num_detections']=num_detections\r\n",
        "\r\n",
        "    # detection_classes should be ints.\r\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\r\n",
        "\r\n",
        "    image_np_with_detections=image_np.copy()\r\n",
        "\r\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "          image_np_with_detections,\r\n",
        "          detections['detection_boxes'],\r\n",
        "          detections['detection_classes'],\r\n",
        "          detections['detection_scores'],\r\n",
        "          category_index,\r\n",
        "          use_normalized_coordinates=True,\r\n",
        "          max_boxes_to_draw=100,     #max number of bounding boxes in the image\r\n",
        "          min_score_thresh=.3,      #min prediction threshold\r\n",
        "          agnostic_mode=False)\r\n",
        "    return image_np_with_detections\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hox8sLURcK3"
      },
      "source": [
        "#Step 18- Running the Inference.\r\n",
        "#Read video in 'TensorFlow/workspace/training_demo/content/sheep_videos.mp4'\r\n",
        "#Detect sheeps and save video that has detected sheep that drawn on rectangle in 'TensorFlow/workspace/training_demo/content/output.avi'\r\n",
        "import cv2\r\n",
        "\r\n",
        "video_capture = cv2.VideoCapture(\"content/sheep_videos.mp4\")\r\n",
        "frame_width = int(video_capture.get(3))\r\n",
        "frame_height = int(video_capture.get(4))\r\n",
        "\r\n",
        "# Define the codec and create VideoWriter object\r\n",
        "out = cv2.VideoWriter('content/output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\r\n",
        "\r\n",
        "while video_capture.isOpened():\r\n",
        "    # Capture frame-by-frame\r\n",
        "    re,frame = video_capture.read()\r\n",
        "    if re==True:\r\n",
        "      Imagenp=show_inference(frame)\r\n",
        "      out.write(Imagenp)\r\n",
        "      if cv2.waitKey(25) & 0xFF == ord('q'):\r\n",
        "          break\r\n",
        "    else:\r\n",
        "      break\r\n",
        "video_capture.release()\r\n",
        "out.release()\r\n",
        "cv2.destroyAllWindows()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
